{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDS Assessment- Coupa Software",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNh1cDFWyyMUwMlArSTZP8x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaypisharody/Coupa_BDS_test/blob/main/BDS_Assessment_Coupa_Software.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task description\n",
        "\n",
        "Historically black colleges and universities (HBCUs) are institutions of higher education in\n",
        "the United States established with the intention of primarily serving the African-American\n",
        "community.\n",
        "\n",
        "\n",
        "Use this exact URL to see the list of certified HBCUs:\n",
        "https://nces.ed.gov/COLLEGENAVIGATOR/?s=all&sp=4&pg=1\n",
        "\n",
        "\n",
        "The expected record count is approximately 100-150 (when all pages are scraped). If your\n",
        "scraper returns more records than this, you might have the incorrect site parameters. Please\n",
        "refer to the above URL exactly as it is.\n",
        "Using Python as the programming language, your task is to scrape the site for all HBCU\n",
        "certified colleges/universities and generate a csv file containing the following data points and\n",
        "data for all scraped colleges/universities. You are free to use any Python libraries of your choice.\n",
        "1. Name\n",
        "2. Street\n",
        "3. City\n",
        "4. State\n",
        "5. Zip\n",
        "6. Phone\n",
        "7. Website\n",
        "8. Type\n",
        "9. Awards\n",
        "10. Campus Setting\n",
        "11. Campus Housing\n",
        "12. Student Population\n",
        "13. Student to Faculty ratio\n"
      ],
      "metadata": {
        "id": "vixdw7LDjR3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install html5lib\n",
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-C3O1WajVpk",
        "outputId": "8e5028f4-53db-45bb-c38b-aeadb3463b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from html5lib) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib) (0.5.1)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "URL = \"https://nces.ed.gov/COLLEGENAVIGATOR/?s=all&sp=4&pg=1\"\n",
        "r = requests.get(URL)\n",
        "\n",
        "soup = BeautifulSoup(r.content, 'html5lib')\n",
        "\n",
        "table = soup.find('table', attrs = {'id':'ctl00_cphCollegeNavBody_ucResultsMain_tblResults'})\n",
        "info=soup.find('td', attrs={'class':'infobutton'})\n",
        "names=soup.find('h2',attrs={'id':'ctl00_cphCollegeNavBody_ucResultsMain_tblResults'})\n",
        "row_nam=[]\n",
        "urls = []\n",
        "for link in table.find_all('a'):\n",
        " urls.append(\"https://nces.ed.gov/COLLEGENAVIGATOR\"+link.get('href'))\n",
        "for j in table.find_all('td'):\n",
        " row_data = j.find_all('h2')\n",
        " row_nam.append([i.text for i in row_data])\n",
        "\n",
        "names=pd.DataFrame(row_nam)\n",
        "names=names.dropna()\n",
        "names=names.drop_duplicates()\n",
        "\n",
        "row_det=[]\n",
        "for j in table.find_all('tr'):\n",
        " row_data = j.find_all('td', attrs={'class':'sra'})\n",
        " row_det.append([i.text for i in row_data])\n",
        "\n",
        "details=pd.DataFrame(row_det)\n",
        "details=details.dropna()\n",
        "details=details.drop_duplicates()\n",
        "\n",
        "weblinks=pd.DataFrame(urls)\n",
        "weblinks=weblinks.iloc[::2]\n",
        "\n",
        "\n",
        "import re\n",
        "row_add=[]\n",
        "streets=[]\n",
        "states=[]\n",
        "zips=[]\n",
        "extras=[]\n",
        "for j in table.find_all('tr'):\n",
        "  row_data= j.find_all('td', attrs={'class':'pbe'})\n",
        "  for r in row_data:\n",
        "    x = re.sub(\"^<td.*</h2>\", \"\", str(r))\n",
        "    x=re.sub(\"</td>$\",\"\",x)\n",
        "    st, ct, s= x.split(',')\n",
        "    streets.append(st+ct)\n",
        "    extras.append(s)\n",
        "    \n",
        "    sss,z=s.rsplit(None,1)\n",
        "    zips.append(z)\n",
        "\n",
        "street=pd.DataFrame(streets)\n",
        "street=street.drop_duplicates() \n",
        "\n",
        "\n",
        "\n",
        "extra=pd.DataFrame(extras) \n",
        "extra=extra.drop_duplicates() \n",
        "\n",
        "zip=pd.DataFrame(zips) \n",
        "zip=zip.drop_duplicates() \n",
        "\n",
        "state_split=[]\n",
        "\n",
        "s=extra.values.tolist()\n",
        "for i in s:\n",
        "  ss,z=str(i).rsplit(None,1)\n",
        "  state_split.append(ss)\n",
        "\n",
        "state=pd.DataFrame(state_split)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "details.insert(0,\"Names\",names.values)\n",
        "details.insert(1,\"Street\",street.values)\n",
        "details.insert(2,\"State\",state.values)\n",
        "details.insert(3,\"zip\",zip.values)\n",
        "details.insert(5,\"URL\",weblinks.values)\n",
        "\n",
        "\n",
        "\n",
        "details.columns=['Name','Street','State','Zip','Phone','Website','Type','Awards','Campus Setting','Campus Housing','Student Population','Student to Faculty ratio']\n",
        "\n",
        "details.to_csv(\"HBCU.csv\")\n",
        "print(\"HBCU.csv created with college details\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMWI0gHpkkd5",
        "outputId": "d077bad0-7291-420d-b7c9-e7b1bf22ad4a"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HBCU.csv created with college details\n"
          ]
        }
      ]
    }
  ]
}